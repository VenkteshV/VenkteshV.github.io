<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Dexter | Venktesh Viswanathan (Venktesh V) </title> <meta name="author" content="Venktesh Viswanathan"> <meta name="description" content="A benchnmark for open-domain complex answering"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://venkteshv.github.io/projects/dexter_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Venktesh Viswanathan (Venktesh V) </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">Supervision </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Dexter</h1> <p class="post-description">A benchnmark for open-domain complex answering</p> </header> <article> <p>Answering complex questions is a difficult task that requires knowledge retrieval. To address this, we propose our easy to use and extensible benchmark composing diverse complex QA tasks and provide a toolkit to evaluate zero-shot retrieval capabilities of state-of-the-art dense and sparse retrieval models in an open-domain setting. Additionally, since context-based reasoning is key to complex QA tasks, we extend our toolkit with various LLM engines. Both the above components together allow our users to evaluate the various components in the Retrieval Augmented Generation pipeline. The detailed paper on Dexter can be found here: <a href="https://arxiv.org/pdf/2406.17158" rel="external nofollow noopener" target="_blank">link to paper</a></p> <p>For components in retrieval we draw inspiration from <a href="https://github.com/beir-cellar/beir" rel="external nofollow noopener" target="_blank">BEIR</a> and reuse some parts of implementation with modification suited to our setup. We thank the authors for open-sourcing their code.</p> <p><a href="https://colab.research.google.com/drive/1UOZ_JuDcWGKvwcPs4ygCEoGCUUgC1PUs?usp=sharing" rel="external nofollow noopener" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p> <h2 id="setup">Setup</h2> <p>To setup from the source first <strong>Clone the repo</strong>, then create a conda environment using <code class="language-plaintext highlighter-rouge">conda create -n bcqa</code> and finally install the package by running: <code class="language-plaintext highlighter-rouge">pip install -e .</code></p> <p>Alternatively you can simply use <code class="language-plaintext highlighter-rouge">pip install dexter-cqa</code></p> <h3 id="datasets">Datasets</h3> <p>All datasets can be found at <a href="https://gitlab.tudelft.nl/venkteshviswan/bcqa_data" rel="external nofollow noopener" target="_blank">Datasets</a></p> <table> <thead> <tr> <th style="text-align: center">Dataset Name</th> <th style="text-align: center">Dataset alias</th> <th style="text-align: center">Homepage</th> <th style="text-align: center">Characteristics</th> <th style="text-align: center">#Questions</th> <th style="text-align: center">Corpus Size</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">MusiqueQA</td> <td style="text-align: center">musiqueqa (2-hop only)</td> <td style="text-align: center"><a href="https://github.com/StonyBrookNLP/musique" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Connected multi-hop reasoning</td> <td style="text-align: center">16.8k</td> <td style="text-align: center">570k</td> </tr> <tr> <td style="text-align: center">WikiMultiHopQA</td> <td style="text-align: center">wikimultihopqa</td> <td style="text-align: center"><a href="https://github.com/Alab-NII/2wikimultihop" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Comparative multi-hop reasoning</td> <td style="text-align: center">190k</td> <td style="text-align: center">570k</td> </tr> <tr> <td style="text-align: center">StrategyQA</td> <td style="text-align: center">strategyqa</td> <td style="text-align: center"><a href="https://allenai.org/data/strategyqa" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Multi-hop reasoning, Implicit Reasoning</td> <td style="text-align: center">2.7k</td> <td style="text-align: center">26.6M</td> </tr> <tr> <td style="text-align: center">AmbigQA</td> <td style="text-align: center">ambignq</td> <td style="text-align: center"><a href="https://nlp.cs.washington.edu/ambigqa/" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Ambiguous Questions</td> <td style="text-align: center">12k</td> <td style="text-align: center">24.3M</td> </tr> <tr> <td style="text-align: center">OTT-QA</td> <td style="text-align: center">ottqa</td> <td style="text-align: center"><a href="https://ott-qa.github.io/" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Table and Text multi-hop reasoning</td> <td style="text-align: center">2.1k</td> <td style="text-align: center">6.5M</td> </tr> <tr> <td style="text-align: center">TAT-QA</td> <td style="text-align: center">tatqa</td> <td style="text-align: center"><a href="https://nextplusplus.github.io/TAT-QA/" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Financial Table and Text multi-hop reasoning</td> <td style="text-align: center">2.9k</td> <td style="text-align: center">7000</td> </tr> <tr> <td style="text-align: center">FinQA</td> <td style="text-align: center">finqa</td> <td style="text-align: center"><a href="https://github.com/czyssrs/FinQA" rel="external nofollow noopener" target="_blank">Link</a></td> <td style="text-align: center">Financial Table and Text multi-hop reasoning</td> <td style="text-align: center">8k</td> <td style="text-align: center">24.8k</td> </tr> </tbody> </table> <p>Note that these are existing datasets that have been extended to an open-domain setting.</p> <h3 id="retrievers">Retrievers</h3> <p>We have experimented with the following retrievers.</p> <table> <thead> <tr> <th style="text-align: center">Name</th> <th style="text-align: center">Paradigm</th> <th style="text-align: center">More</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">BM25</td> <td style="text-align: center">Lexical</td> <td style="text-align: center"><a href="https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">SPLADE</td> <td style="text-align: center">Sparse</td> <td style="text-align: center"><a href="https://github.com/naver/splade" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">DPR</td> <td style="text-align: center">Dense</td> <td style="text-align: center"><a href="https://github.com/facebookresearch/DPR" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">ANCE</td> <td style="text-align: center">Dense</td> <td style="text-align: center"><a href="https://github.com/microsoft/ANCE" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">tas-b</td> <td style="text-align: center">Dense</td> <td style="text-align: center"><a href="https://github.com/sebastian-hofstaetter/tas-balanced-dense-retrieval" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">MPNet</td> <td style="text-align: center">Dense</td> <td style="text-align: center"><a href="https://github.com/microsoft/MPNet" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">Contriever</td> <td style="text-align: center">Dense</td> <td style="text-align: center"><a href="https://github.com/facebookresearch/contriever" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> <tr> <td style="text-align: center">ColBERTv2</td> <td style="text-align: center">Late-Interaction</td> <td style="text-align: center"><a href="https://github.com/stanford-futuredata/ColBERT" rel="external nofollow noopener" target="_blank">Link</a></td> </tr> </tbody> </table> <p><strong>Retrieving over large corpus collections:</strong> Since some of the datasets have corpus collection with large sizes (millions), we also support chunking of corpus when doing retrieval. To avoid storing docs in memory inspired by the issue `https://github.com/beir-cellar/beir/pull/117’ we maintain a list of top-k docs with scores when computing scores chunkwise using heapq.</p> <p>If you have a retriever that you use and find to work favourably please let us know.</p> <h3 id="llm-models">LLM Models</h3> <p>We use the folowing LLM models in our internal benchmarking:</p> <ul> <li>OpenAI models</li> <li>Mistral</li> <li>Llama</li> <li> <p>FlanT5</p> <p>Our toolkit is flexible and can support further new generative models. It will be an ongoing effort and we welcome contributions. If you have a LLM that you use and find to work favourably please let us know.</p> </li> </ul> <h3 id="project-structure">Project Structure</h3> <ul> <li>data <ul> <li>datastructures: Basic data classes for question, answer and others needed in the pipeline.</li> <li>dataloaders: Loaders that take raw json/zip file data and convert them to the format needed in the pipeline</li> </ul> </li> <li>retriever: Retrievers that take the data loaders and perform retrieval to produce results. <ul> <li>dense : dense retrievers like ColBERTv2,ANCE, Contriever, MpNet, DPR and Tas-B</li> <li>lexical: lexical retrievers like BM25</li> <li>sparse: Sparse retrievers like SPLADE</li> </ul> </li> <li>llms: LLM engine orchestrator and implementation for inference using LLama2, Mistral, OpenAI models and Flan-T5 ( more models to come soon.)</li> <li>config: Configuration files with constants and initialization.</li> <li>tests: test cases for the above components</li> <li>utils: utilities needed in the pipeline like retrieval accuracy calculation and matching.</li> </ul> <h2 id="running-evaluation">Running Evaluation</h2> <p>Below is an example script demonstrating how to load a dataset from our benchmark (ambignq here), feed it into one of our retrievers(ANCE here), and evaluate the retrieval quality against the relevance labels provided by the dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dexter.config.constants</span> <span class="kn">import</span> <span class="n">Split</span>
<span class="kn">from</span> <span class="n">dexter.data.loaders.RetrieverDataset</span> <span class="kn">import</span> <span class="n">RetrieverDataset</span>
<span class="kn">from</span> <span class="n">dexter.retriever.dense.ANCE</span> <span class="kn">import</span> <span class="n">ANCE</span>
<span class="kn">from</span> <span class="n">dexter.utils.metrics.SimilarityMatch</span> <span class="kn">import</span> <span class="n">CosineSimilarity</span>
<span class="kn">from</span> <span class="n">dexter.utils.metrics.retrieval.RetrievalMetrics</span> <span class="kn">import</span> <span class="n">RetrievalMetrics</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="c1"># Ensure in config.ini the path to the raw data files are linked under [Data-Path]
</span>    <span class="c1"># ambignq = '&lt;path to the data file&gt;
</span>    <span class="c1"># ambignq-corpus = '&lt;path to the corpus file&gt;'
</span>
    <span class="c1"># You can set the split to one of Split.DEV, Split.TEST or Split.TRAIN
</span>    <span class="c1"># Setting tokenizer=None only loads only the raw data processed into our standard data classes, if tokenizer is set, the data is also tokenized and stored in the loader.
</span>    <span class="n">loader</span> <span class="o">=</span> <span class="nc">RetrieverDataset</span><span class="p">(</span><span class="sh">"</span><span class="s">ambignq</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">ambignq-corpus</span><span class="sh">"</span><span class="p">,</span>
                               <span class="sh">"</span><span class="s">config.ini</span><span class="sh">"</span><span class="p">,</span> <span class="n">Split</span><span class="p">.</span><span class="n">DEV</span><span class="p">,</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

    <span class="c1"># Initialize your retriever configuration
</span>    <span class="n">config_instance</span> <span class="o">=</span> <span class="nc">DenseHyperParams</span><span class="p">(</span><span class="n">query_encoder_path</span><span class="o">=</span><span class="sh">"</span><span class="s">facebook/contriever</span><span class="sh">"</span><span class="p">,</span>
                                     <span class="n">document_encoder_path</span><span class="o">=</span><span class="sh">"</span><span class="s">facebook/contriever</span><span class="sh">"</span>
                                     <span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">show_progress_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># From data loader loads list of queries, corpus and relevance labels.
</span>    <span class="n">queries</span><span class="p">,</span> <span class="n">qrels</span><span class="p">,</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">qrels</span><span class="p">()</span>

    <span class="c1">#Perform Retrieval
</span>    <span class="n">contrvr_search</span> <span class="o">=</span> <span class="nc">Contriever</span><span class="p">(</span><span class="n">config_instance</span><span class="p">)</span>   
    <span class="n">similarity_measure</span> <span class="o">=</span> <span class="nc">CosineSimilarity</span><span class="p">()</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">contrvr_search</span><span class="p">.</span><span class="nf">retrieve</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span><span class="n">queries</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="n">similarity_measure</span><span class="p">,</span><span class="n">chunk</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">chunksize</span><span class="o">=</span><span class="mi">400000</span><span class="p">)</span>


    <span class="c1">#Evaluate retrieval metrics
</span>    <span class="n">metrics</span> <span class="o">=</span> <span class="nc">RetrievalMetrics</span><span class="p">(</span><span class="n">k_values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="nf">evaluate_retrieval</span><span class="p">(</span><span class="n">qrels</span><span class="o">=</span><span class="n">qrels</span><span class="p">,</span><span class="n">results</span><span class="o">=</span><span class="n">response</span><span class="p">))</span>
</code></pre></div></div> <h3 id="running-evaluation-for-results-in-paper">Running Evaluation for Results in Paper</h3> <p>All evaluation scripts dataset wise can be found in the evaluation folder</p> <p><strong>Example TAT-QA ( When building from source)</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl https://gitlab.tudelft.nl/venkteshviswan/bcqa_data/-/raw/main/tatqa.zip -o tatqa.zip
</code></pre></div></div> <p>In evaluation/config.ini configure the corresponding paths to downloaded files configure project root directory to PYTHONPATH variable</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export PYTHONPATH=/path

export OPENAI_KEY=&lt;your openai key&gt;

export huggingface_token = &lt;your huggingface token to access llama2  &gt;

</code></pre></div></div> <p>If you are using Elasticsearch (ES) installation &gt;8 please export the following values based on your ES setup</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export ca_certs = &lt;path to http_ca.crt path in your ES installation&gt;

export http_auth = &lt;your elasticsearch password&gt;
</code></pre></div></div> <p><strong>To reproduce dpr results run</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 evaluation/tatqa/run_dpr_inference.py
</code></pre></div></div> <p><strong>To reproduce colbert results run</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 evaluation/tatqa/test_tctcolbert_inference.py
</code></pre></div></div> <p>Similarly other retrievers can be also run using other scripts in the folder</p> <p><strong>To reproduce our LLM results</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export OPENAI_KEY="&lt;you key here&gt;"
</code></pre></div></div> <p>To run openAI model using colbert docs, run:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 evaluation/tatqa/llms/run_rag_few_shot_cot.py
</code></pre></div></div> <p>The above experiment would help get numbers for FEW-SHOT-COT for gpt-3.5-turbo which can be checked with Table 3.</p> <h2 id="building-your-own-custom-dataset">Building your own custom dataset</h2> <p>You can quickly build your own dataset in three steps:</p> <p><strong>1) Loading the question, answer and evidence records</strong></p> <p>The base data loader by default takes a json file of the format</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'id':'..','question':'..','answer':'..'}]
</code></pre></div></div> <p>Each of the train, test and val splits should under their own json files named under your dir</p> <ul> <li>/dir_path/train.json</li> <li>/dir_path/test.json</li> <li>/dir_path/validation.json</li> </ul> <p>If you want to create your custom loader: Within the directory data/dataloaders, Create your Dataloader by extending from BaseDataLoader</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">class</span> <span class="nc">MyDataLoader</span><span class="p">(</span><span class="n">BaseDataLoader</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">load_raw_dataset</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">split</span><span class="p">):</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">load_json</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
        
        <span class="n">records</span> <span class="o">=</span>  <span class="sh">'''</span><span class="s">your code to transform the elements in json to List[Sample(idx:str,question:Question,answer:Answer,evidence:Evidence)]</span><span class="sh">'''</span>
        <span class="c1"># If needed you can also extend from Question,Answer and Evidence dataclasses to form your own types
</span>        <span class="n">self</span><span class="p">.</span><span class="n">raw_data</span> <span class="o">=</span> <span class="n">records</span>
    <span class="k">def</span> <span class="nf">load_tokenized</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">'''</span><span class="s"> If required overwrite this function to build custom tkenization method of your dataset </span><span class="sh">'''</span>

</code></pre></div></div> <p>Under config.ini:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>my-dataset = 'dir_path'
</code></pre></div></div> <p><strong>2) Loading the corpus</strong> To load your own corpus you can provide a json file of the standard format:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{"idx":{"text":"...","title":"..",'type":"table/text"}}
</code></pre></div></div> <p>Under config.ini add:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>my-dataset-corpus = '&lt; path to the json file of above format &gt;'
</code></pre></div></div> <p><strong>3) Add your dataset alias to constants</strong></p> <p>Within config.constants:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Dataset</span><span class="p">:</span>
    <span class="n">AMBIGQA</span> <span class="o">=</span> <span class="sh">"</span><span class="s">ambignq</span><span class="sh">"</span>
    <span class="n">WIKIMULTIHOPQA</span> <span class="o">=</span> <span class="sh">"</span><span class="s">wikimultihopqa</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="n">MY_DATASET</span> <span class="o">=</span> <span class="sh">"</span><span class="s">my-dataset</span><span class="sh">"</span>
</code></pre></div></div> <p>and within data/loader/DataLoaderFactory.py:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">def</span> <span class="nf">create_dataloader</span><span class="p">(</span>
<span class="bp">...</span>
        <span class="k">if</span> <span class="n">Dataset</span><span class="p">.</span><span class="n">AMBIGQA</span> <span class="ow">in</span> <span class="n">dataloader_name</span><span class="p">:</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">AmbigQADataLoader</span>
        <span class="k">elif</span> <span class="n">Dataset</span><span class="p">.</span><span class="n">FINQA</span> <span class="ow">in</span> <span class="n">dataloader_name</span><span class="p">:</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">FinQADataLoader</span>
        <span class="p">..</span>
        <span class="k">elif</span> <span class="n">Dataset</span><span class="p">.</span><span class="n">MY_DATASET</span> <span class="ow">in</span> <span class="n">dataloader_name</span><span class="p">:</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">MyDataLoader</span>
    
</code></pre></div></div> <p>Your dataset is now ready to be loaded and used.</p> <p><strong>a) You can load the dataloader as:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loader_factory</span> <span class="o">=</span> <span class="nc">DataLoaderFactory</span><span class="p">()</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">loader_factory</span><span class="p">.</span><span class="nf">create_dataloader</span><span class="p">(</span><span class="sh">"</span><span class="s">my-dataset</span><span class="sh">"</span><span class="p">,</span> <span class="n">config_path</span><span class="o">=</span><span class="sh">"</span><span class="s">config.ini</span><span class="sh">"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">Split</span><span class="p">.</span><span class="n">DEV</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <p><strong>b) You can load the corpus as:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loader</span> <span class="o">=</span> <span class="nc">PassageDataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="sh">"</span><span class="s">my-dataset-corpus</span><span class="sh">"</span><span class="p">,</span><span class="n">subset_ids</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">config_path</span><span class="o">=</span><span class="sh">"</span><span class="s">config.ini</span><span class="sh">"</span><span class="p">,</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <p><strong>c) You can load RetrieverDataset as:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loader</span> <span class="o">=</span> <span class="nc">RetrieverDataset</span><span class="p">(</span><span class="sh">"</span><span class="s">my-dataset</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">my-dataset-corpus</span><span class="sh">"</span><span class="p">,</span>
                               <span class="sh">"</span><span class="s">config.ini</span><span class="sh">"</span><span class="p">,</span> <span class="n">Split</span><span class="p">.</span><span class="n">DEV</span><span class="p">,</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <h3 id="building-your-own-retrievers">Building your own retrievers</h3> <p>To build your own retriever you can extend from the class bcqa/retriever/BaseRetriever.py and use it in your evaluation script.</p> <h3 id="citing--authors">Citing &amp; Authors</h3> <p>This work is done with <a href="https://venkteshv.github.io/#home" rel="external nofollow noopener" target="_blank">Venktesh Vishwanath</a> and Deepali Prabhu.</p> <p>For citing please use the following bibtex</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">venky:2024:dexter</span><span class="p">,</span>
      <span class="na">title</span><span class="p">=</span><span class="s">{DEXTER: A Benchmark for open-domain Complex Question Answering using LLMs}</span><span class="p">,</span> 
      <span class="na">author</span><span class="p">=</span><span class="s">{Venktesh V. and Deepali Prabhu and Avishek Anand}</span><span class="p">,</span>
      <span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
      <span class="na">eprint</span><span class="p">=</span><span class="s">{2406.17158}</span><span class="p">,</span>
      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.CL}</span><span class="p">,</span>
      <span class="na">url</span><span class="p">=</span><span class="s">{https://arxiv.org/abs/2406.17158}</span><span class="p">,</span> 
<span class="p">}</span>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Venktesh Viswanathan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 17, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. * indicates equal contribution.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"Teaching",description:"I have served as Assisting/Co-Instructor for several Masters level courses and Undergraduate Level courses at TU Delft during my PostDoc and IIIT-Delhi during my PhD.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-supervision",title:"Supervision",description:"Students I have supervised or currently supervising",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-invited-talk-on-lt-strong-gt-robust-and-efficient-frontier-pipelines-for-complex-knowledge-intensive-tasks-in-the-era-of-llms-lt-strong-gt-as-part-of-lt-a-href-quot-https-cni-iisc-ac-in-seminars-2025-02-04-quot-gt-lt-em-gt-cni-semiar-series-iisc-lt-em-gt-lt-a-gt-iisc-banglore",title:"\ud83c\udfa4 Invited talk on &lt;strong&gt;\u201cRobust and efficient frontier pipelines for complex knowledge intensive tasks in the era of LLMs\u201d&lt;/strong&gt; as part of &lt;a href=&quot;https://cni.iisc.ac.in/seminars/2025-02-04/&quot;&gt;&lt;em&gt;CNI Semiar Series @ IISC&lt;/em&gt;&lt;/a&gt;, IISC, banglore.",description:"",section:"News"},{id:"news-paper-accepted-at-lt-a-href-quot-https-icml-cc-conferences-2024-quot-gt-naacl-2025-lt-a-gt-titled-lt-em-gt-sunar-semantic-uncertainty-based-neighborhood-aware-retrieval-for-complex-qa-lt-em-gt",title:"Paper accepted at &lt;a href=&quot;https://icml.cc/Conferences/2024&quot;&gt;NAACL 2025&lt;/a&gt;, titled &lt;em&gt;\u201cSUNAR: Semantic Uncertainty based Neighborhood Aware Retrieval for Complex QA\u201d&lt;/em&gt;.   \ud83c\udf89",description:"",section:"News"},{id:"news-paper-accepted-at-the-lt-a-href-quot-https-ieeexplore-ieee-org-xpl-recentissue-jsp-punumber-69-quot-gt-ecir-ir4good-lt-a-gt-titled-lt-em-gt-flashcheck-exploration-of-efficient-evidence-retrieval-for-fast-fact-checking-lt-em-gt",title:"Paper accepted at the &lt;a href=&quot;https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69&quot;&gt;ECIR IR4Good&lt;/a&gt;, titled &lt;em&gt;\u201cFlashCheck: Exploration of Efficient Evidence Retrieval for Fast Fact-Checking\u201d&lt;/em&gt;. \ud83c\udf89",description:"",section:"News"},{id:"news-paper-accepted-at-lt-a-href-quot-https-icml-cc-conferences-2024-quot-gt-emnlp-2024-lt-a-gt-titled-lt-strong-gt-explora-efficient-exemplar-subset-selection-for-complex-reasoning-lt-strong-gt",title:"Paper accepted at &lt;a href=&quot;https://icml.cc/Conferences/2024&quot;&gt;EMNLP 2024&lt;/a&gt;, titled &lt;strong&gt;\u201cEXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning\u201d&lt;/strong&gt;.   \ud83c\udf89",description:"",section:"News"},{id:"news-organized-the-lt-a-href-quot-https-dir2023-github-io-dir2023-quot-gt-dutch-belgian-ir-conference-lt-a-gt-or-dir-2023-fun-talks-with-some-great-minds-in-ir",title:"\ud83d\udce2 Organized the &lt;a href=&quot;https://dir2023.github.io/DIR2023/&quot;&gt;Dutch-Belgian IR Conference&lt;/a&gt; or DIR 2023! Fun talks with some great minds in IR \ud83c\udf10 \ud83d\udd0d",description:"",section:"News"},{id:"projects-dexter",title:"Dexter",description:"A benchnmark for open-domain complex answering",section:"Projects",handler:()=>{window.location.href="/projects/dexter_project/"}},{id:"projects-quantemp",title:"QuanTemp",description:"An open-domain benchmark to verify claims with quantities and temporal expressions",section:"Projects",handler:()=>{window.location.href="/projects/quantemp_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%76.%76%69%73%77%61%6E%61%74%68%61%6E-%31@%74%75%64%65%6C%66%74.%6E%6C","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=FrDPEc0AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/VenkteshV","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/venktesh-v-78099a135# your LinkedIn user name","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/vvenki22","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>